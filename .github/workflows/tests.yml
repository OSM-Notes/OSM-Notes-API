# CI/CD Pipeline - OSM-Notes-API
# Unified workflow structure for Node.js/TypeScript projects
# Author: Andres Gomez (AngocA)
# Version: 2026-01-27

name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run weekly on Monday at 2am UTC
    - cron: '0 2 * * 1'
  workflow_dispatch:

permissions:
  contents: read

env:
  NODE_VERSION: '18'
  DB_NAME: osm_notes_api_test
  DB_USER: osm_notes_test_user
  DB_PASSWORD: osm_notes_test_pass

jobs:
  # ============================================================================
  # STAGE 1: Quality Checks
  # ============================================================================
  quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

      - name: Run TypeScript type check
        run: npm run type-check

      - name: Check code formatting
        run: npm run format:check

      - name: Check Prettier formatting for other files
        run: |
          if command -v prettier &> /dev/null || npm list -g prettier &> /dev/null; then
            npx prettier --check "**/*.{md,json,yaml,yml,css,html}" --ignore-path .prettierignore || echo "Prettier formatting issues found (non-blocking)"
          else
            npm install -g prettier
            prettier --check "**/*.{md,json,yaml,yml,css,html}" --ignore-path .prettierignore || echo "Prettier formatting issues found (non-blocking)"
          fi

      - name: Check Python formatting (if Python files exist)
        continue-on-error: true
        run: |
          PYTHON_FILES=$(find . -name "*.py" -not -path "./node_modules/*" -not -path "./.git/*" | head -5)
          if [ -n "$PYTHON_FILES" ]; then
            if command -v black &> /dev/null; then
              echo "$PYTHON_FILES" | xargs black --check --line-length 100 || echo "Python formatting issues found (non-blocking)"
            elif command -v ruff &> /dev/null; then
              echo "$PYTHON_FILES" | xargs ruff check || echo "Python linting issues found (non-blocking)"
            else
              echo "Black/Ruff not installed, skipping Python format check"
            fi
          fi

  # ============================================================================
  # STAGE 2: Build
  # ============================================================================
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build TypeScript
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 1

  # ============================================================================
  # STAGE 3: Tests
  # ============================================================================
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: [quality]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run all tests (master test command)
        run: npm test

      - name: Generate coverage report
        run: npm run test:coverage
        continue-on-error: true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage/lcov.info
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage/
          retention-days: 7

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: ${{ env.DB_NAME }}
          POSTGRES_USER: ${{ env.DB_USER }}
          POSTGRES_PASSWORD: ${{ env.DB_PASSWORD }}
        options: >-
          --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping" --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 6379:6379
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Wait for PostgreSQL
        run: |
          until pg_isready -h localhost -p 5432 -U ${{ env.DB_USER }}; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done

      - name: Setup test database
        run: |
          PGPASSWORD=${{ env.DB_PASSWORD }} psql -h localhost -U ${{ env.DB_USER }} -d postgres -c "CREATE DATABASE ${{ env.DB_NAME }};" || true
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}

      - name: Run integration tests
        run: npm run test:integration
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: ${{ env.DB_NAME }}
          DB_USER: ${{ env.DB_USER }}
          DB_PASSWORD: ${{ env.DB_PASSWORD }}
          REDIS_HOST: localhost
          REDIS_PORT: 6379
          NODE_ENV: test

  # ============================================================================
  # STAGE 4: Security
  # ============================================================================
  security:
    name: Security Audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run npm audit
        run: |
          npm audit --audit-level=moderate || {
            echo "⚠️ npm audit found vulnerabilities"
            echo "Run 'npm audit fix' to fix automatically fixable issues"
            exit 0
          }

      - name: Upload audit results
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: npm-audit-results
          path: npm-audit.json
          retention-days: 30

  # ============================================================================
  # STAGE 5: Summary
  # ============================================================================
  summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [quality, build, test, integration-tests, security]
    if: always()
    steps:
      - name: Check all results
        run: |
          echo "## CI Results Summary - OSM-Notes-API" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.quality.result }}" == "success" ]; then
            echo "✅ Code Quality: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Code Quality: FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.build.result }}" == "success" ]; then
            echo "✅ Build: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Build: FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.test.result }}" == "success" ]; then
            echo "✅ Tests: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Tests: FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.integration-tests.result }}" == "success" ]; then
            echo "✅ Integration Tests: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Integration Tests: FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.security.result }}" == "success" ] || [ "${{ needs.security.result }}" == "skipped" ]; then
            echo "✅ Security Audit: PASSED/SKIPPED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Security Audit: FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          # Exit with error if any job failed
          if [ "${{ needs.quality.result }}" != "success" ] || \
             [ "${{ needs.build.result }}" != "success" ] || \
             [ "${{ needs.test.result }}" != "success" ] || \
             [ "${{ needs.integration-tests.result }}" != "success" ] || \
             ([ "${{ needs.security.result }}" != "success" ] && [ "${{ needs.security.result }}" != "skipped" ]); then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "❌ Some checks failed. Please review the logs above." >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "✅ All checks passed!" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
